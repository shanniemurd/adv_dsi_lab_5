{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCwQQFkU3v5"
   },
   "source": [
    "### 2.   Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lupPwT3qWqyq"
   },
   "source": [
    "**[2.1]** Download the dataset into the `data/raw` folder:https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iqVIqdjbWqyq",
    "outputId": "28601707-563e-48d3-a364-35f5124576e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-10 05:53:23--  https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv\n",
      "Resolving code.datasciencedojo.com (code.datasciencedojo.com)... 167.99.111.153\n",
      "Connecting to code.datasciencedojo.com (code.datasciencedojo.com)|167.99.111.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1966669 (1.9M) [text/plain]\n",
      "Saving to: ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv.1’\n",
      "\n",
      "PRSA_data_2010.1.1- 100%[===================>]   1.88M   569KB/s    in 3.6s    \n",
      "\n",
      "2022-03-10 05:53:28 (532 KB/s) - ‘../data/raw/PRSA_data_2010.1.1-2014.12.31.csv.1’ saved [1966669/1966669]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ../data/raw https://code.datasciencedojo.com/datasciencedojo/datasets/raw/master/Beijing%20PM2.5/PRSA_data_2010.1.1-2014.12.31.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cZojBrtWRz0"
   },
   "source": [
    "**[2.2]** Launch the magic commands for auto-relaoding external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "0p7MGcUSWSAr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#Solution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAIO_Y5Z9_Ay"
   },
   "source": [
    "**[2.3]** Import the pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "2VRE9JYD9_Kk"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Zy6Oq8pkuB"
   },
   "source": [
    "**[2.4]** Load the data in a dataframe called `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Q1iETWjDftMg"
   },
   "outputs": [],
   "source": [
    "#Solution:\n",
    "df = pd.read_csv('../data/raw/PRSA_data_2010.1.1-2014.12.31.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLyMcoNCsx2k"
   },
   "source": [
    "**[2.5]** Display the first 5 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "xvnbhiPhs0ZP",
    "outputId": "e53ecd49-2f83-4391-8d44-6a02fdcc13df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQgeYjQDs12m"
   },
   "source": [
    "**[2.6]** Display the dimensions (shape) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg_89DlAs1_w",
    "outputId": "7b5cdeac-b62b-4a49-dd1f-db9dbb336fd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43824, 13)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyle1PCws7B0"
   },
   "source": [
    "**[2.7]** Display the summary (info) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1msvlh7s7Lt",
    "outputId": "7e607270-809a-4587-ac90-5e168d8f4ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43824 entries, 0 to 43823\n",
      "Data columns (total 13 columns):\n",
      "No       43824 non-null int64\n",
      "year     43824 non-null int64\n",
      "month    43824 non-null int64\n",
      "day      43824 non-null int64\n",
      "hour     43824 non-null int64\n",
      "pm2.5    41757 non-null float64\n",
      "DEWP     43824 non-null int64\n",
      "TEMP     43824 non-null float64\n",
      "PRES     43824 non-null float64\n",
      "cbwd     43824 non-null object\n",
      "Iws      43824 non-null float64\n",
      "Is       43824 non-null int64\n",
      "Ir       43824 non-null int64\n",
      "dtypes: float64(4), int64(8), object(1)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWLgqm2YtAgP"
   },
   "source": [
    "**[2.8]** Display the descriptive statistics of df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "FQLSaoXltAp-",
    "outputId": "6fb0ec68-3920-451b-a5e6-20b708a8f3d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>41757.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "      <td>43824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>6.523549</td>\n",
       "      <td>15.727820</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>98.613215</td>\n",
       "      <td>1.817246</td>\n",
       "      <td>12.448521</td>\n",
       "      <td>1016.447654</td>\n",
       "      <td>23.889140</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.194916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12651.043435</td>\n",
       "      <td>1.413842</td>\n",
       "      <td>3.448572</td>\n",
       "      <td>8.799425</td>\n",
       "      <td>6.922266</td>\n",
       "      <td>92.050387</td>\n",
       "      <td>14.433440</td>\n",
       "      <td>12.198613</td>\n",
       "      <td>10.268698</td>\n",
       "      <td>50.010635</td>\n",
       "      <td>0.760375</td>\n",
       "      <td>1.415867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10956.750000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21912.500000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32868.250000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>21.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43824.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>994.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>585.600000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 No          year         month           day          hour  \\\n",
       "count  43824.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean   21912.500000   2012.000000      6.523549     15.727820     11.500000   \n",
       "std    12651.043435      1.413842      3.448572      8.799425      6.922266   \n",
       "min        1.000000   2010.000000      1.000000      1.000000      0.000000   \n",
       "25%    10956.750000   2011.000000      4.000000      8.000000      5.750000   \n",
       "50%    21912.500000   2012.000000      7.000000     16.000000     11.500000   \n",
       "75%    32868.250000   2013.000000     10.000000     23.000000     17.250000   \n",
       "max    43824.000000   2014.000000     12.000000     31.000000     23.000000   \n",
       "\n",
       "              pm2.5          DEWP          TEMP          PRES           Iws  \\\n",
       "count  41757.000000  43824.000000  43824.000000  43824.000000  43824.000000   \n",
       "mean      98.613215      1.817246     12.448521   1016.447654     23.889140   \n",
       "std       92.050387     14.433440     12.198613     10.268698     50.010635   \n",
       "min        0.000000    -40.000000    -19.000000    991.000000      0.450000   \n",
       "25%       29.000000    -10.000000      2.000000   1008.000000      1.790000   \n",
       "50%       72.000000      2.000000     14.000000   1016.000000      5.370000   \n",
       "75%      137.000000     15.000000     23.000000   1025.000000     21.910000   \n",
       "max      994.000000     28.000000     42.000000   1046.000000    585.600000   \n",
       "\n",
       "                 Is            Ir  \n",
       "count  43824.000000  43824.000000  \n",
       "mean       0.052734      0.194916  \n",
       "std        0.760375      1.415867  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max       27.000000     36.000000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miQ6SiKlscLx"
   },
   "source": [
    "### 3. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtuF1V6ctwn-"
   },
   "source": [
    "**[3.1]** Create a copy of `df` and save it into a variable called `df_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "HrXR7NCLtwxB"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWnL2dh5W2Th"
   },
   "source": [
    "**[3.2]** Remove the column `No` as it is an identifier for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "TdbDsjpLW2ev"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.drop('No', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsKJOOyZXGOw"
   },
   "source": [
    "**[3.3]** Remove the missing values from the target variable `pm2.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "AhJBqXnbXGY-"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K9x8C7dXbis"
   },
   "source": [
    "**[3.4]** Reset the indexes of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "83iRE5u5XbtD"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1RrTCBRDybQ"
   },
   "source": [
    "**[3.5]** Import `StandardScaler` and `OneHotEncoder` from `sklearn.preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "aezRs9S3Dyl0"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pKaCxasERAt"
   },
   "source": [
    "**[3.6]** Create a list called `num_cols` that contains `year`, `DEWP`, `TEMP`, `PRES`, `Iws`, `Is`, `Ir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "yDwCmIXvERJO"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "num_cols = ['year', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l0Hkri1FVrv"
   },
   "source": [
    "**[3.7]** Instantiate a `StandardScaler` and called it `sc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "x_yCjMqgFV1u"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2v1vLMWTofp"
   },
   "source": [
    "**[3.8]** Fit and transform the numeric feature of `df_cleaned` and replace the data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "dfUpbRYSTopS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt8YYcHuTsDs"
   },
   "source": [
    "**[3.9]** Create a list called `cat_cols` that contains `month`, `day`, `hour`, `cbwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "z6isEtGBTsNz"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "cat_cols = ['month', 'day', 'hour', 'cbwd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sWy8I5FYVhU"
   },
   "source": [
    "**[3.10]** Instantiate a `OneHotEncoder` and called it `ohe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "OyWdvAEwYVrW"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "ohe = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guu_QM_KN8Aw"
   },
   "source": [
    "**[3.11]** Perform One-Hot encoding on `cat_cols` and save them into a dataframe called `X_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Gv7PFYRONv0o"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "X_cat = pd.DataFrame(ohe.fit_transform(df_cleaned[cat_cols]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo-a_TQpYyOA"
   },
   "source": [
    "**[3.12]** Extract the feature names from `ohe` and replace the names of the columns of the `X_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "L5RmoZq1YyiQ"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "X_cat.columns = ohe.get_feature_names(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjseyrsDYzdO"
   },
   "source": [
    "**[3.13]** Drop the original columns of `cat_cols` from `df_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ysPhEhxfYztM"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned.drop(cat_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UjZDvdZN7N6"
   },
   "source": [
    "**[3.14]** Concatenate `df_cleaned` with `X_cat` and save the result to a variable called `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "qsTYYnsSN7Wl"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "X = pd.concat([df_cleaned, X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx4JAuiuzaIe"
   },
   "source": [
    "**[3.15]** Import `split_sets_by_time` and `save_sets` from `src.data.sets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "OOefCMTLzaRQ"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.data.sets import split_sets_by_time, save_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7DCMLV6TBjr"
   },
   "source": [
    "**[3.16]** Split the data into training and testing sets with 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ICjW0_-4TBvu"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_by_time(X, target_col='pm2.5', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bvx44G2_Wqy4"
   },
   "source": [
    "**[3.17]** Create the following folder: `data/processed/beijing_pollution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Jm3cSvCSWqy5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/mkdir: cannot create directory ‘../data/processed/beijing_pollution’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../data/processed/beijing_pollution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J--rD8iNRH8B"
   },
   "source": [
    "**[3.18]** Save the sets in the `data/processed/beijing_pollution` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "_wO5x1RlRIE6"
   },
   "outputs": [],
   "source": [
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../data/processed/beijing_pollution/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8MNBrC4Zgz6"
   },
   "source": [
    "### 4. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lt1lE8lJ9zS"
   },
   "source": [
    "**[4.1]** Import `NullModel` from `src.models.null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "2xufkK8VJ99s"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.models.null import NullModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJNZfvA4dJ9X"
   },
   "source": [
    "**[4.2]** Instantiate a `NullModel` and call `.fit_predict()` on the training target to extract your predictions into a variable called `y_base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "fev4FWAYdU1G"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "baseline_model = NullModel()\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRLIZeci7cfW"
   },
   "source": [
    "**[4.3]** Import `print_reg_perf` from `src.models.performance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Z1Jt8WX57cqn"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.performance import print_reg_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlv1ny8Jg10r"
   },
   "source": [
    "**[4.4]** Print the regression metrics for this baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "n4DoenMJg2AC",
    "outputId": "aecd3131-a35a-4370-baf4-36d5309d146e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Training: 92.82545840756482\n",
      "MAE Training: 69.67082209440568\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "print_reg_perf(y_base, y_train, set_name='Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUEbyrm2ZzhL"
   },
   "source": [
    "### 5. Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faMubeDzZzuX"
   },
   "source": [
    "**[5.1]** Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "vBSoR7LTZz3-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKBNkwgmgVPQ"
   },
   "source": [
    "**[5.2]** Create in `src/models/pytorch.py` a class called `PytorchRegression` that inherits from `nn.Module` with:\n",
    "- `num_features` as input parameter\n",
    "- attributes:\n",
    "    - `layer_1`: fully-connected layer with 128 neurons\n",
    "    - `layer_out`: fully-connected layer with 1 neurons\n",
    "- methods:\n",
    "    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "siffJESGfZDt"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "class PytorchRegression(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchRegression, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 128)\n",
    "        self.layer_out = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)))\n",
    "        x = self.layer_out(x)\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORcJNo4ygaRa"
   },
   "source": [
    "**[5.3]** Instantiate `PytorchRegression` with the correct number of input feature and save it into a variable called `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "QkXUqKMcgaZN"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import PytorchRegression\n",
    "\n",
    "model = PytorchRegression(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBxCIn10ZDAF"
   },
   "source": [
    "**[5.4]** Create  in `src/models/pytorch.py` a function called `get_device()` with:\n",
    "- Logics: check if cuda is available and return `cuda:0` if that is the case `cpu` otherwise\n",
    "- Output: device to be used by Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "c6oNYKJEZDM4"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu') # don't have GPU \n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR22BA8dZnKz"
   },
   "source": [
    "**[5.5]** Set `model` to use the device available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "nmw1xla2ZnYT",
    "outputId": "cf03f71b-e351-4c65-85de-333497000da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchRegression(\n",
       "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
       "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekaUYYjqgfcF"
   },
   "source": [
    "**[5.6]** Print the architecture of `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "h8Jmfhk0MQ0i",
    "outputId": "e57e6a4a-9378-4a8b-bb4b-36c2c3dd3d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchRegression(\n",
      "  (layer_1): Linear(in_features=78, out_features=128, bias=True)\n",
      "  (layer_out): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IbQs_iqinhq"
   },
   "source": [
    "### 6. Create Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRx25yhYjDVB"
   },
   "source": [
    "**[6.1]** Import `Dataset` and `DataLoader` from `torch.utils.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "fFshbWLVjDiU"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEueJp-0iy2T"
   },
   "source": [
    "**[6.2]** Create in `src/models/pytorch.py`a class called `PytorchDataset` that inherits from `torch.utils.data.Dataset` with:\n",
    "- `X` ans `y` as input parameters\n",
    "- attributes:\n",
    "    - `X_tensor`: X converted to Pytorch tensor\n",
    "    - `y_tensor`: y converted to Pytorch tensor\n",
    "- methods:\n",
    "    - `__getitem__(index)`\n",
    "        Return features and target for a given index\n",
    "    - `__len__`\n",
    "        Return the number of observations\n",
    "    - `to_tensor(data)`\n",
    "        Convert Pandas Series to Pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "SoP-YD7EizA_"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "class PytorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pytorch dataset\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_tensor : Pytorch tensor\n",
    "        Features tensor\n",
    "    y_tensor : Pytorch tensor\n",
    "        Target tensor\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __getitem__(index)\n",
    "        Return features and target for a given index\n",
    "    __len__\n",
    "        Return the number of observations\n",
    "    to_tensor(data)\n",
    "        Convert Pandas Series to Pytorch tensor\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, X, y):\n",
    "        self.X_tensor = self.to_tensor(X)\n",
    "        self.y_tensor = self.to_tensor(y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_tensor[index], self.y_tensor[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_tensor)\n",
    "    \n",
    "    def to_tensor(self, data):\n",
    "        return torch.Tensor(np.array(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55TZNjVLjzxP"
   },
   "source": [
    "**[6.3]** Import this class from `src/models/pytorch` and convert all sets to PytorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "ls8gm3JIjz7A"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjypmrX2sojQ"
   },
   "source": [
    "**[6.4]** Import DataLoader from `torch.utils.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "F0NlzTRAsouj"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppK2EFnZs8mb"
   },
   "source": [
    "### 7. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE8fVHin92-6"
   },
   "source": [
    "**[7.1]** Instantiate a `nn.MSELoss()` and save it into a variable called `criterion` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "oludTfN193I-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sxqDnYJ_CxY"
   },
   "source": [
    "**[7.2]** Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.001 as learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "GUxr7KPY_C-y"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7L45Xp3aJJc"
   },
   "source": [
    "**[7.3]** Create a function called `train_regression()` that will perform forward and back propagation and calculate loss and RMSE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPf8514oaJTt"
   },
   "outputs": [],
   "source": [
    "def train_regression(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, collate_fn=None):\n",
    "    \"\"\"Train a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class)\n",
    "        \n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), np.sqrt(train_loss / len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nXfK0H-_1aM"
   },
   "source": [
    "**[7.4]** Create a function called `test_regression()` that will perform forward and calculate loss and RMSE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjsdSLle_1mb"
   },
   "outputs": [],
   "source": [
    "def test_regression(test_data, model, criterion, batch_size, device, collate_fn=None):\n",
    "    \"\"\"Calculate performance of a Pytorch regresssion model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        RMSE Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class)\n",
    "            \n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "    return test_loss / len(test_data), np.sqrt(test_loss / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7OmK12vAD1O"
   },
   "source": [
    "**[7.5]** Create 2 variables called `N_EPOCHS` and `BATCH_SIZE` that will take respectively 5 and 32 as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "O7IyO0ugAD9d"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLMMkp9XAGMf"
   },
   "source": [
    "**[7.6]** Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "DJTG4hvIddpv",
    "outputId": "242f89a5-f1e4-42ad-e49c-809505326d68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\tLoss: 350.2497\t|\tRMSE: 18.7\n",
      "\t(valid)\tLoss: 248.8868\t|\tRMSE: 15.8\n",
      "Epoch: 1\n",
      "\t(train)\tLoss: 273.6832\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 236.8293\t|\tRMSE: 15.4\n",
      "Epoch: 2\n",
      "\t(train)\tLoss: 272.7032\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 237.3120\t|\tRMSE: 15.4\n",
      "Epoch: 3\n",
      "\t(train)\tLoss: 272.5862\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 236.7346\t|\tRMSE: 15.4\n",
      "Epoch: 4\n",
      "\t(train)\tLoss: 272.3568\t|\tRMSE: 16.5\n",
      "\t(valid)\tLoss: 236.4065\t|\tRMSE: 15.4\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import train_regression, test_regression\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_rmse = train_regression(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_rmse = test_regression(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\tLoss: {train_loss:.4f}\\t|\\tRMSE: {train_rmse:.1f}')\n",
    "    print(f'\\t(valid)\\tLoss: {valid_loss:.4f}\\t|\\tRMSE: {valid_rmse:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2W8S3ewcyKl"
   },
   "source": [
    "**[7.7]** Save the model into the `models` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "gPfmTNxocyXC"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "torch.save(model, \"../models/pytorch_reg_pm2_5.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyacNiLhz7BF"
   },
   "source": [
    "### 8.   Assess Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3-lk01m0F1S"
   },
   "source": [
    "**[8.1]** Assess the model performance on the testing set and print its scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "IRzOY6wK0FJ9",
    "outputId": "c7da0826-a933-493d-fa0c-4e3be0d7cffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 276.0827\t|\tRMSE: 16.6\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_rmse = test_regression(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tRMSE: {test_rmse:.1f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AdvDSI_Lab5_Exercise1_SolutionsSM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
