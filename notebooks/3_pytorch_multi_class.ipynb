{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NCwQQFkU3v5"
   },
   "source": [
    "### 2.   Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cZojBrtWRz0"
   },
   "source": [
    "**[2.1]** Launch the magic commands for auto-relaoding external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0p7MGcUSWSAr"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAIO_Y5Z9_Ay"
   },
   "source": [
    "**[2.2]** Import the pandas and numpy packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2VRE9JYD9_Kk"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbRDgod3_3Yv"
   },
   "source": [
    "**[2.3]** Create a variable called `file_url` containing th url to the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gcaDN6V3_3q9"
   },
   "outputs": [],
   "source": [
    "#Solution\n",
    "file_url = 'https://raw.githubusercontent.com/aso-uts/applied_ds/master/unit3/dataset/Car%20Evaluation.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Zy6Oq8pkuB"
   },
   "source": [
    "**[2.4]** Load the data in a dataframe called `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q1iETWjDftMg"
   },
   "outputs": [],
   "source": [
    "#Solution:\n",
    "df = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLyMcoNCsx2k"
   },
   "source": [
    "**[2.5]** Display the first 5 rows of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KtyrLDYvC6QA",
    "outputId": "a4b1c8a4-1cc4-452a-c107-3e04dd0950e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying_price maintenance_cost doors persons_capacity luggage_boot safety  \\\n",
       "0        vhigh            vhigh     2                2        small    low   \n",
       "1        vhigh            vhigh     2                2        small    med   \n",
       "2        vhigh            vhigh     2                2        small   high   \n",
       "3        vhigh            vhigh     2                2          med    low   \n",
       "4        vhigh            vhigh     2                2          med    med   \n",
       "\n",
       "  evaluation  \n",
       "0      unacc  \n",
       "1      unacc  \n",
       "2      unacc  \n",
       "3      unacc  \n",
       "4      unacc  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQgeYjQDs12m"
   },
   "source": [
    "**[2.6]** Display the dimensions (shape) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg_89DlAs1_w",
    "outputId": "7b5cdeac-b62b-4a49-dd1f-db9dbb336fd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyle1PCws7B0"
   },
   "source": [
    "**[2.7]** Display the summary (info) of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Wbmsgqv7C-Sr",
    "outputId": "95931739-9fc5-4858-e9b4-4edab09a85b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      "buying_price        1728 non-null object\n",
      "maintenance_cost    1728 non-null object\n",
      "doors               1728 non-null object\n",
      "persons_capacity    1728 non-null object\n",
      "luggage_boot        1728 non-null object\n",
      "safety              1728 non-null object\n",
      "evaluation          1728 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWLgqm2YtAgP"
   },
   "source": [
    "**[2.8]** Display the descriptive statistics of df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j_p104o4DAZr",
    "outputId": "9139547f-18cb-4d2c-aa31-50e6574dceb5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_price</th>\n",
       "      <th>maintenance_cost</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons_capacity</th>\n",
       "      <th>luggage_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>432</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       buying_price maintenance_cost  doors persons_capacity luggage_boot  \\\n",
       "count          1728             1728   1728             1728         1728   \n",
       "unique            4                4      4                3            3   \n",
       "top            high             high  5more                2        small   \n",
       "freq            432              432    432              576          576   \n",
       "\n",
       "       safety evaluation  \n",
       "count    1728       1728  \n",
       "unique      3          4  \n",
       "top      high      unacc  \n",
       "freq      576       1210  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aWaMMzBBVC5"
   },
   "source": [
    "**[2.9]** Save the dataframe locally in the `data/raw` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WeiW3cRdBeUV"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df.to_csv('../data/raw/car_evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miQ6SiKlscLx"
   },
   "source": [
    "### 3. Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtuF1V6ctwn-"
   },
   "source": [
    "**[3.1]** Create a copy of `df` and save it into a variable called `df_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HrXR7NCLtwxB"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWnL2dh5W2Th"
   },
   "source": [
    "**[3.2]** Create a dictionary called `cats_dict` that contains the categorical variables as keys and their respective values sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TdbDsjpLW2ev"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "cats_dict = {\n",
    "    'buying_price': [['low', 'med', 'high', 'vhigh']],\n",
    "    'maintenance_cost': [['low', 'med', 'high', 'vhigh']],\n",
    "    'doors': [['2', '3', '4', '5more']],\n",
    "    'persons_capacity': [['2', '4', 'more']],\n",
    "    'luggage_boot': [['small', 'med', 'big']],\n",
    "    'safety': [['low', 'med', 'high']],\n",
    "    'evaluation': [['unacc', 'acc', 'good', 'vgood']],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1RrTCBRDybQ"
   },
   "source": [
    "**[3.3]** Import `StandardScaler` and `OrdinalEncoder` from `sklearn.preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "aezRs9S3Dyl0"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pKaCxasERAt"
   },
   "source": [
    "**[3.4]** Iterate through the elements of `cast_dict`, instantiate an OrdinalEncoder() and transform the values of each column with this encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yDwCmIXvERJO"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "for col, cats in cats_dict.items():\n",
    "    col_encoder = OrdinalEncoder(categories=cats)\n",
    "    df_cleaned[col] = col_encoder.fit_transform(df_cleaned[[col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1K02gpSWyX2"
   },
   "source": [
    "**[3.5]** Create a list called `num_cols` that contains all numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dCMtu-X9WyiE"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "num_cols = ['buying_price', 'maintenance_cost', 'doors', 'persons_capacity', 'luggage_boot', 'safety']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l0Hkri1FVrv"
   },
   "source": [
    "**[3.6]** Instantiate a `StandardScaler` and called it `sc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x_yCjMqgFV1u"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2v1vLMWTofp"
   },
   "source": [
    "**[3.7]** Fit and transform the numeric feature of `df_cleaned` and replace the data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dfUpbRYSTopS"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned[num_cols] = sc.fit_transform(df_cleaned[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sWy8I5FYVhU"
   },
   "source": [
    "**[3.8]** Convert the column `evaluation` as integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OyWdvAEwYVrW"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "df_cleaned['evaluation'] = df_cleaned['evaluation'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx4JAuiuzaIe"
   },
   "source": [
    "**[3.9]** Import `split_sets_random` and `save_sets` from `src.data.sets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OOefCMTLzaRQ"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.data.sets import split_sets_random, save_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7DCMLV6TBjr"
   },
   "source": [
    "**[3.10]** Split the data into training and testing sets with 80-20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ICjW0_-4TBvu"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_sets_random(df_cleaned, target_col='evaluation', test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1UxjgGHW_ji"
   },
   "source": [
    "**[3.11]** Create the following folder: ../data/processed/car_evaluation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9Y4YIfFWW_ji"
   },
   "outputs": [],
   "source": [
    "!mkdir ../data/processed/car_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J--rD8iNRH8B"
   },
   "source": [
    "**[3.12]** Save the sets in the `data/processed/car_evaluation` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "_wO5x1RlRIE6"
   },
   "outputs": [],
   "source": [
    "save_sets(X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, path='../data/processed/car_evaluation/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55TZNjVLjzxP"
   },
   "source": [
    "**[3.13]** Import this class from `src/models/pytorch` and convert all sets to PytorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ls8gm3JIjz7A"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import PytorchDataset\n",
    "\n",
    "train_dataset = PytorchDataset(X=X_train, y=y_train)\n",
    "val_dataset = PytorchDataset(X=X_val, y=y_val)\n",
    "test_dataset = PytorchDataset(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8MNBrC4Zgz6"
   },
   "source": [
    "### 4. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lt1lE8lJ9zS"
   },
   "source": [
    "**[4.1]** Import `NullModel` from `src.models.null`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2xufkK8VJ99s"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "from src.models.null import NullModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJNZfvA4dJ9X"
   },
   "source": [
    "**[4.2]** Instantiate a `NullModel` and call `.fit_predict()` on the training target to extract your predictions into a variable called `y_base`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "fev4FWAYdU1G"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "baseline_model = NullModel(target_type='classification')\n",
    "y_base = baseline_model.fit_predict(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRLIZeci7cfW"
   },
   "source": [
    "**[4.3]** Import `print_class_perf` from `src.models.performance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Z1Jt8WX57cqn"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.performance import print_class_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlv1ny8Jg10r"
   },
   "source": [
    "**[4.4]** Print the classification metrics for this baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "n4DoenMJg2AC",
    "outputId": "21f0339e-75b4-4c38-96da-e1f04f08af15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training: 0.6988416988416989\n",
      "F1 Training: 0.5749561249561249\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "print_class_perf(y_base, y_train, set_name='Training', average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUEbyrm2ZzhL"
   },
   "source": [
    "### 5. Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faMubeDzZzuX"
   },
   "source": [
    "**[5.1]** Import `torch`, `torch.nn` as `nn` and `torch.nn.functional` as `F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vBSoR7LTZz3-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKBNkwgmgVPQ"
   },
   "source": [
    "**[5.2]** Create in `src/models/pytorch.py` a class called `PytorchMultiClass` that inherits from `nn.Module` with:\n",
    "- `num_features` as input parameter\n",
    "- attributes:\n",
    "    - `layer_1`: fully-connected layer with 32 neurons\n",
    "    - `layer_out`: fully-connected layer with 4 neurons\n",
    "    - `softmax`: softmax function\n",
    "- methods:\n",
    "    - `forward()` with `inputs` as input parameter, perform ReLU and DropOut on the fully-connected layer followed by the output layer with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siffJESGfZDt"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "class PytorchMultiClass(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(PytorchMultiClass, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(num_features, 32)\n",
    "        self.layer_out = nn.Linear(32, 4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.layer_1(x)), training=self.training)\n",
    "        x = self.layer_out(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORcJNo4ygaRa"
   },
   "source": [
    "**[5.3]** Instantiate `PytorchMultiClass` with the correct number of input feature and save it into a variable called `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "QkXUqKMcgaZN"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import PytorchMultiClass\n",
    "\n",
    "model = PytorchMultiClass(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR22BA8dZnKz"
   },
   "source": [
    "**[5.4]** Import `get_device()` from `src.models.pytorch` and set `model` to use the device available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nmw1xla2ZnYT",
    "outputId": "8d419bdd-e32d-42b4-e55b-d83b580b02d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PytorchMultiClass(\n",
       "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
       "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekaUYYjqgfcF"
   },
   "source": [
    "**[5.5]** Print the architecture of `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "h8Jmfhk0MQ0i",
    "outputId": "9c940fff-8b2f-466b-c874-c7e595ba3633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PytorchMultiClass(\n",
      "  (layer_1): Linear(in_features=6, out_features=32, bias=True)\n",
      "  (layer_out): Linear(in_features=32, out_features=4, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppK2EFnZs8mb"
   },
   "source": [
    "### 6. Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE8fVHin92-6"
   },
   "source": [
    "**[6.1]** Instantiate a `nn.CrossEntropyLoss()` and save it into a variable called `criterion` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oludTfN193I-"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sxqDnYJ_CxY"
   },
   "source": [
    "**[6.2]** Instantiate a `torch.optim.Adam()` optimizer with the model's parameters and 0.1 as learning rate and save it into a variable called `optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "GUxr7KPY_C-y"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7L45Xp3aJJc"
   },
   "source": [
    "**[6.3]** Create a function called `train_classification()` that will perform forward and back propagation and calculate loss and Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPf8514oaJTt"
   },
   "outputs": [],
   "source": [
    "def train_classification(train_data, model, criterion, optimizer, batch_size, device, scheduler=None, generate_batch=None):\n",
    "    \"\"\"Train a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    optimizer: torch.optim\n",
    "        Optimizer\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Pytorch Scheduler used for updating learning rate\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Make predictions\n",
    "        output = model(feature)\n",
    "        \n",
    "        # Calculate loss for given batch\n",
    "        loss = criterion(output, target_class.long())\n",
    "\n",
    "        # Calculate global loss\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate global accuracy\n",
    "        train_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    return train_loss / len(train_data), train_acc / len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nXfK0H-_1aM"
   },
   "source": [
    "**[6.5]** Create a function called `test_classification()` that will perform forward and calculate loss and accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjsdSLle_1mb"
   },
   "outputs": [],
   "source": [
    "def test_classification(test_data, model, criterion, batch_size, device, generate_batch=None):\n",
    "    \"\"\"Calculate performance of a Pytorch multi-class classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Pytorch dataset\n",
    "    model: torch.nn.Module\n",
    "        Pytorch Model\n",
    "    criterion: function\n",
    "        Loss function\n",
    "    bacth_size : int\n",
    "        Number of observations per batch\n",
    "    device : str\n",
    "        Name of the device used for the model\n",
    "    collate_fn : function\n",
    "        Function defining required pre-processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Loss score\n",
    "    Float:\n",
    "        Accuracy Score\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    # Create data loader\n",
    "    data = DataLoader(test_data, batch_size=batch_size, collate_fn=generate_batch)\n",
    "    \n",
    "    # Iterate through data by batch of observations\n",
    "    for feature, target_class in data:\n",
    "        \n",
    "        # Load data to specified device\n",
    "        feature, target_class = feature.to(device), target_class.to(device)\n",
    "        \n",
    "        # Set no update to gradients\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Make predictions\n",
    "            output = model(feature)\n",
    "            \n",
    "            # Calculate loss for given batch\n",
    "            loss = criterion(output, target_class.long())\n",
    "\n",
    "            # Calculate global loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            test_acc += (output.argmax(1) == target_class).sum().item()\n",
    "\n",
    "    return test_loss / len(test_data), test_acc / len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7OmK12vAD1O"
   },
   "source": [
    "**[6.5]** Create 2 variables called `N_EPOCHS` and `BATCH_SIZE` that will take respectively 50 and 32 as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "O7IyO0ugAD9d"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLMMkp9XAGMf"
   },
   "source": [
    "**[6.6]** Create a for loop that will iterate through the specified number of epochs and will train the model with the training set and assess the performance on the validation set and print their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DJTG4hvIddpv",
    "outputId": "17ae43a9-eb43-4b56-cfca-f5a18f95a8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\t(train)\t|\tLoss: 0.0314\t|\tAcc: 75.3%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 81.8%\n",
      "Epoch: 1\n",
      "\t(train)\t|\tLoss: 0.0304\t|\tAcc: 79.1%\n",
      "\t(valid)\t|\tLoss: 0.0290\t|\tAcc: 82.9%\n",
      "Epoch: 2\n",
      "\t(train)\t|\tLoss: 0.0296\t|\tAcc: 81.3%\n",
      "\t(valid)\t|\tLoss: 0.0292\t|\tAcc: 82.7%\n",
      "Epoch: 3\n",
      "\t(train)\t|\tLoss: 0.0297\t|\tAcc: 81.2%\n",
      "\t(valid)\t|\tLoss: 0.0288\t|\tAcc: 83.5%\n",
      "Epoch: 4\n",
      "\t(train)\t|\tLoss: 0.0295\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 85.3%\n",
      "Epoch: 5\n",
      "\t(train)\t|\tLoss: 0.0294\t|\tAcc: 82.2%\n",
      "\t(valid)\t|\tLoss: 0.0288\t|\tAcc: 83.5%\n",
      "Epoch: 6\n",
      "\t(train)\t|\tLoss: 0.0303\t|\tAcc: 79.7%\n",
      "\t(valid)\t|\tLoss: 0.0281\t|\tAcc: 86.1%\n",
      "Epoch: 7\n",
      "\t(train)\t|\tLoss: 0.0296\t|\tAcc: 81.1%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 85.0%\n",
      "Epoch: 8\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.1%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 9\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 10\n",
      "\t(train)\t|\tLoss: 0.0294\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 11\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.1%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 12\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.2%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 13\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.5%\n",
      "\t(valid)\t|\tLoss: 0.0305\t|\tAcc: 78.3%\n",
      "Epoch: 14\n",
      "\t(train)\t|\tLoss: 0.0294\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0292\t|\tAcc: 82.4%\n",
      "Epoch: 15\n",
      "\t(train)\t|\tLoss: 0.0297\t|\tAcc: 81.5%\n",
      "\t(valid)\t|\tLoss: 0.0293\t|\tAcc: 82.1%\n",
      "Epoch: 16\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 82.7%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 85.0%\n",
      "Epoch: 17\n",
      "\t(train)\t|\tLoss: 0.0295\t|\tAcc: 81.8%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 18\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 82.9%\n",
      "\t(valid)\t|\tLoss: 0.0288\t|\tAcc: 83.5%\n",
      "Epoch: 19\n",
      "\t(train)\t|\tLoss: 0.0298\t|\tAcc: 81.1%\n",
      "\t(valid)\t|\tLoss: 0.0287\t|\tAcc: 83.8%\n",
      "Epoch: 20\n",
      "\t(train)\t|\tLoss: 0.0299\t|\tAcc: 80.6%\n",
      "\t(valid)\t|\tLoss: 0.0291\t|\tAcc: 82.7%\n",
      "Epoch: 21\n",
      "\t(train)\t|\tLoss: 0.0294\t|\tAcc: 82.3%\n",
      "\t(valid)\t|\tLoss: 0.0283\t|\tAcc: 85.0%\n",
      "Epoch: 22\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.2%\n",
      "\t(valid)\t|\tLoss: 0.0284\t|\tAcc: 85.0%\n",
      "Epoch: 23\n",
      "\t(train)\t|\tLoss: 0.0292\t|\tAcc: 82.8%\n",
      "\t(valid)\t|\tLoss: 0.0287\t|\tAcc: 84.1%\n",
      "Epoch: 24\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 82.7%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.1%\n",
      "Epoch: 25\n",
      "\t(train)\t|\tLoss: 0.0289\t|\tAcc: 83.7%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "Epoch: 26\n",
      "\t(train)\t|\tLoss: 0.0279\t|\tAcc: 86.4%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 27\n",
      "\t(train)\t|\tLoss: 0.0282\t|\tAcc: 86.1%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 28\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 85.2%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 29\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 84.3%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.4%\n",
      "Epoch: 30\n",
      "\t(train)\t|\tLoss: 0.0299\t|\tAcc: 80.5%\n",
      "\t(valid)\t|\tLoss: 0.0287\t|\tAcc: 84.1%\n",
      "Epoch: 31\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.3%\n",
      "\t(valid)\t|\tLoss: 0.0285\t|\tAcc: 85.0%\n",
      "Epoch: 32\n",
      "\t(train)\t|\tLoss: 0.0288\t|\tAcc: 84.1%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 33\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.4%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 34\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.4%\n",
      "\t(valid)\t|\tLoss: 0.0292\t|\tAcc: 82.4%\n",
      "Epoch: 35\n",
      "\t(train)\t|\tLoss: 0.0295\t|\tAcc: 81.7%\n",
      "\t(valid)\t|\tLoss: 0.0282\t|\tAcc: 85.5%\n",
      "Epoch: 36\n",
      "\t(train)\t|\tLoss: 0.0293\t|\tAcc: 82.0%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.1%\n",
      "Epoch: 37\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.9%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 38\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.3%\n",
      "\t(valid)\t|\tLoss: 0.0281\t|\tAcc: 86.1%\n",
      "Epoch: 39\n",
      "\t(train)\t|\tLoss: 0.0290\t|\tAcc: 83.0%\n",
      "\t(valid)\t|\tLoss: 0.0277\t|\tAcc: 87.3%\n",
      "Epoch: 40\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 41\n",
      "\t(train)\t|\tLoss: 0.0287\t|\tAcc: 84.0%\n",
      "\t(valid)\t|\tLoss: 0.0286\t|\tAcc: 84.7%\n",
      "Epoch: 42\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.6%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 43\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.8%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 44\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.3%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.7%\n",
      "Epoch: 45\n",
      "\t(train)\t|\tLoss: 0.0284\t|\tAcc: 85.2%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 46\n",
      "\t(train)\t|\tLoss: 0.0285\t|\tAcc: 84.9%\n",
      "\t(valid)\t|\tLoss: 0.0280\t|\tAcc: 86.4%\n",
      "Epoch: 47\n",
      "\t(train)\t|\tLoss: 0.0286\t|\tAcc: 84.7%\n",
      "\t(valid)\t|\tLoss: 0.0279\t|\tAcc: 86.4%\n",
      "Epoch: 48\n",
      "\t(train)\t|\tLoss: 0.0283\t|\tAcc: 85.4%\n",
      "\t(valid)\t|\tLoss: 0.0276\t|\tAcc: 87.6%\n",
      "Epoch: 49\n",
      "\t(train)\t|\tLoss: 0.0291\t|\tAcc: 83.1%\n",
      "\t(valid)\t|\tLoss: 0.0289\t|\tAcc: 83.5%\n"
     ]
    }
   ],
   "source": [
    "# Solution:\n",
    "from src.models.pytorch import train_classification, test_classification\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train_classification(train_dataset, model=model, criterion=criterion, optimizer=optimizer, batch_size=BATCH_SIZE, device=device)\n",
    "    valid_loss, valid_acc = test_classification(val_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "\n",
    "    print(f'Epoch: {epoch}')\n",
    "    print(f'\\t(train)\\t|\\tLoss: {train_loss:.4f}\\t|\\tAcc: {train_acc * 100:.1f}%')\n",
    "    print(f'\\t(valid)\\t|\\tLoss: {valid_loss:.4f}\\t|\\tAcc: {valid_acc * 100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2W8S3ewcyKl"
   },
   "source": [
    "**[6.7]** Save the model into the `models` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "gPfmTNxocyXC"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "torch.save(model, \"../models/pytorch_multi_car_evaluation.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3-lk01m0F1S"
   },
   "source": [
    "**[6.8]** Assess the model performance on the testing set and print its scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "IRzOY6wK0FJ9",
    "outputId": "ae72fd29-81d5-42b1-c759-f9f1a7bd75b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss: 0.0299\t|\tAccuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test_classification(test_dataset, model=model, criterion=criterion, batch_size=BATCH_SIZE, device=device)\n",
    "print(f'\\tLoss: {test_loss:.4f}\\t|\\tAccuracy: {test_acc:.1f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AdvDSI_Lab5_Exercise3_Solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
